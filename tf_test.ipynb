{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 30.0\n",
      "type of a : <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "type of c : <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "a: 5.0\n",
      "x: 5.0\n",
      "30.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    " \n",
    "# Build a graph.\n",
    "a = tf.constant(5.0)\n",
    "b = tf.constant(6.0)\n",
    "c = a * b\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "x=sess.run(a)\n",
    "# Evaluate the tensor `c`.\n",
    "print(\"c:\",sess.run(c))\n",
    "print(\"type of a :\",type(a ))\n",
    "print(\"type of c :\",type(c )) #<class 'tensorflow.python.framework.ops.Tensor'>\n",
    "print(\"a:\",sess.run(a))\n",
    "print(\"x:\",x) \n",
    " \n",
    "a = tf.constant(5.0)\n",
    "b = tf.constant(6.0)\n",
    "c = a * b\n",
    "with tf.Session():\n",
    "  # We can also use 'c.eval()' here.\n",
    "  print(c.eval())\n",
    "sess.run(tf.Print(c,[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.0\n",
      "10.0\n"
     ]
    }
   ],
   "source": [
    "a=tf.placeholder(tf.float32)\n",
    "b=tf.placeholder(tf.float32)\n",
    "c=tf.add(a,b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c,feed_dict={a:10,b:30}))\n",
    "    print(sess.run(a,feed_dict={a:10,b:30}))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5975862  0.18598771]\n",
      " [0.39765155 0.14281064]]\n",
      "(5, 2)\n",
      "[[0.36735054 0.59657368]\n",
      " [0.42055205 0.07220875]\n",
      " [0.65058957 0.62223439]\n",
      " [0.65095764 0.60003768]\n",
      " [0.72083482 0.99427141]]\n",
      "<TensorSliceDataset shapes: (2,), types: tf.float64>\n",
      "<class 'tensorflow.python.data.ops.dataset_ops.TensorSliceDataset'>\n",
      "sess.run(datas): [0.36735054 0.59657368]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = tf.placeholder(tf.float32, shape=(2, 2))\n",
    "y = tf.matmul(x, x)\n",
    " \n",
    "with tf.Session() as sess:\n",
    "  rand_array = np.random.rand(2, 2)  \n",
    "  print(sess.run(y, feed_dict={x: rand_array}))\n",
    "k=np.random.uniform(size=(5, 2))\n",
    "print(k.shape)\n",
    "print(k)\n",
    "#dataset = tf.data.Dataset.from_tensor_slices(np.random.uniform(size=(5, 2))) \n",
    "dataset = tf.data.Dataset.from_tensor_slices(k) \n",
    "\n",
    "print(dataset)\n",
    "print(type(dataset))\n",
    "#with tf.Session() as sess:\n",
    "#    print(sess.run(dataset))#Can not convert a TensorSliceDataset into a Tensor or Operation.)\n",
    "\n",
    "datas=dataset.make_one_shot_iterator().get_next()\n",
    "sess=tf.Session()\n",
    "print(\"sess.run(datas):\",sess.run(datas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "f    4\n",
      "e    5\n",
      "dtype: int64\n",
      "2\n",
      "(5,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s=pd.Series([1,2,3,4,5],index=['a','b','c','f','e'])\n",
    "print(s)\n",
    "print(s['b'])\n",
    "print(s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cols\n",
      "a     1\n",
      "b     2\n",
      "c     3\n",
      "d     4\n",
      "e     5\n",
      "df['cols']: \n",
      " a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "e    5\n",
      "Name: cols, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "df = pd.DataFrame([1, 2, 3, 4, 5], columns=['cols'], index=['a','b','c','d','e'])\n",
    "print(df)\n",
    "print(\"df['cols']: \\n\",df['cols'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df2    col1  col2  col3\n",
      "a     1     2     3\n",
      "b     4     5     6\n",
      "a    3\n",
      "b    6\n",
      "Name: col3, dtype: int64\n",
      "Index(['a', 'b'], dtype='object')\n",
      "Index(['col1', 'col2', 'col3'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['a', 'b'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame([[1, 2, 3],[4, 5, 6]], columns=['col1','col2','col3'], index=['a','b'])\n",
    "print(\"df2\",df2)\n",
    "print(df2[\"col3\"])\n",
    "print(df2.index)\n",
    "print(df2.columns)\n",
    "df2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col1    1\n",
       "col2    2\n",
       "col3    3\n",
       "Name: a, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.loc['a']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'city': ['Beijing', 'Shanghai', 'Guangzhou', 'Shenzhen', 'Hangzhou', 'Chongqing'], 'year': [2016, 2017, 2016, 2017, 2016, 2016], 'population': [2100, 2300, 1000, 700, 500, 500]}\n",
      "        city  year  population\n",
      "0    Beijing  2016        2100\n",
      "1   Shanghai  2017        2300\n",
      "2  Guangzhou  2016        1000\n",
      "3   Shenzhen  2017         700\n",
      "4   Hangzhou  2016         500\n",
      "5  Chongqing  2016         500\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset\n",
    "feature_values = np.array([[10, 7, 4], [3, 2, 1]])\n",
    "num_buckets=4\n",
    "boundaries = np.arange(1.0, num_buckets) / num_buckets\n",
    "#quantiles = feature_values.quantile(boundaries) \n",
    "population={'city':['Beijing','Shanghai','Guangzhou','Shenzhen','Hangzhou','Chongqing'],\n",
    "            'year':[2016,2017,2016,2017,2016,2016],\n",
    "            'population':[2100,2300,1000,700,500,500]\n",
    "            }\n",
    "print(population)\n",
    "population=pd.DataFrame(population)   ###\n",
    "print(population)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apts:\n",
      " Beijing      55000.0\n",
      "Shanghai     60000.0\n",
      "shenzhen     50000.0\n",
      "Hangzhou     20000.0\n",
      "Guangzhou    45000.0\n",
      "Suzhou           NaN\n",
      "Name: income, dtype: float64\n",
      "df1：\n",
      "             income\n",
      "Beijing    55000.0\n",
      "Shanghai   60000.0\n",
      "shenzhen   50000.0\n",
      "Hangzhou   20000.0\n",
      "Guangzhou  45000.0\n",
      "Suzhou         NaN\n",
      "apts:\n",
      " Beijing      55000.0\n",
      "Shanghai     60000.0\n",
      "shenzhen     70000.0\n",
      "Hangzhou     20000.0\n",
      "Guangzhou    45000.0\n",
      "Suzhou           NaN\n",
      "Name: income, dtype: float64\n",
      "less_than_50000 apts:\n",
      " Beijing      55000.0\n",
      "Shanghai     60000.0\n",
      "shenzhen     70000.0\n",
      "Hangzhou     40000.0\n",
      "Guangzhou    40000.0\n",
      "Suzhou           NaN\n",
      "Name: income, dtype: float64\n",
      "apts2 :\n",
      " Beijing      10000\n",
      "Shanghai      8000\n",
      "shenzhen      6000\n",
      "Tianjin      40000\n",
      "Guangzhou     7000\n",
      "Chongqing    30000\n",
      "dtype: int64\n",
      "apts :\n",
      " Beijing      65000.0\n",
      "Chongqing    64000.0\n",
      "Guangzhou    47000.0\n",
      "Hangzhou     64000.0\n",
      "Shanghai     68000.0\n",
      "Suzhou       64000.0\n",
      "Tianjin      64000.0\n",
      "shenzhen     76000.0\n",
      "dtype: float64\n",
      "              apts    apts2\n",
      "Beijing    65000.0  10000.0\n",
      "Chongqing  64000.0  30000.0\n",
      "Guangzhou  47000.0   7000.0\n",
      "Hangzhou   64000.0      NaN\n",
      "Shanghai   68000.0   8000.0\n",
      "Suzhou     64000.0      NaN\n",
      "Tianjin    64000.0  40000.0\n",
      "shenzhen   76000.0   6000.0\n",
      "boundaries :\n",
      " [0.   0.25 0.5  0.75]\n",
      "returns:\n",
      " [0.00    47000.0\n",
      "0.25    64000.0\n",
      "0.50    64000.0\n",
      "0.75    65750.0\n",
      "Name: apts, dtype: float64, 0.00     6000.0\n",
      "0.25     7250.0\n",
      "0.50     9000.0\n",
      "0.75    25000.0\n",
      "Name: apts2, dtype: float64]\n",
      "quantiles:\n",
      "          apts    apts2\n",
      "0.00  47000.0   6000.0\n",
      "0.25  64000.0   7250.0\n",
      "0.50  64000.0   9000.0\n",
      "0.75  65750.0  25000.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apts</th>\n",
       "      <th>apts2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Beijing</th>\n",
       "      <td>65000.0</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chongqing</th>\n",
       "      <td>64000.0</td>\n",
       "      <td>30000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guangzhou</th>\n",
       "      <td>47000.0</td>\n",
       "      <td>7000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hangzhou</th>\n",
       "      <td>64000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shanghai</th>\n",
       "      <td>68000.0</td>\n",
       "      <td>8000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              apts    apts2\n",
       "Beijing    65000.0  10000.0\n",
       "Chongqing  64000.0  30000.0\n",
       "Guangzhou  47000.0   7000.0\n",
       "Hangzhou   64000.0      NaN\n",
       "Shanghai   68000.0   8000.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities={'Beijing':55000,'Shanghai':60000,'shenzhen':50000,'Hangzhou':20000,'Guangzhou':45000,'Suzhou':None}\n",
    "apts=pd.Series(cities,name='income')\n",
    "print(\"apts:\\n\",apts)\n",
    "df1=pd.DataFrame(apts)\n",
    "print(\"df1：\\n\",df1)\n",
    "apts['shenzhen']=70000\n",
    "print(\"apts:\\n\",apts)\n",
    "less_than_50000=(apts<50000)\n",
    "apts[less_than_50000]=40000\n",
    "print(\"less_than_50000 apts:\\n\",apts)\n",
    "apts2=pd.Series({'Beijing':10000,'Shanghai':8000,'shenzhen':6000,'Tianjin':40000,'Guangzhou':7000,'Chongqing':30000})\n",
    "print(\"apts2 :\\n\",apts2)\n",
    "apts=apts+apts2\n",
    "apts[apts.isnull()]=apts.mean()\n",
    "print(\"apts :\\n\",apts)\n",
    "\n",
    "df=pd.DataFrame({'apts':apts,'apts2':apts2})   ###\n",
    "print(df)\n",
    "feature_values=df\n",
    "num_buckets=4\n",
    "boundaries = np.arange(0.0, num_buckets) / num_buckets\n",
    "print(\"boundaries :\\n\",boundaries )\n",
    "quantiles = feature_values.quantile(boundaries) \n",
    "returns=[quantiles[q] for q in quantiles.keys()]\n",
    "print(\"returns:\\n\",returns)\n",
    "print(\"quantiles:\\n\",quantiles)\n",
    "df.describe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df:\n",
      "               apts    apts2  bonus    income\n",
      "Beijing    65000.0  10000.0   2000  147000.0\n",
      "Chongqing  64000.0  30000.0   2000  175000.0\n",
      "Guangzhou  47000.0   7000.0   2000  106500.0\n",
      "Hangzhou   64000.0      NaN   2000       NaN\n",
      "Shanghai   68000.0   8000.0   2000  150000.0\n",
      "Suzhou     64000.0      NaN   2000       NaN\n",
      "Tianjin    64000.0  40000.0   2000  190000.0\n",
      "shenzhen   76000.0   6000.0   2000  163000.0\n",
      "tmp_df2:\n",
      "       apts    apts2  bonus    income\n",
      "0  65000.0  10000.0   2000  147000.0\n",
      "1  64000.0  30000.0   2000  175000.0\n",
      "2  47000.0   7000.0   2000  106500.0\n",
      "3  64000.0      NaN   2000       NaN\n",
      "4  68000.0   8000.0   2000  150000.0\n",
      "5  64000.0      NaN   2000       NaN\n",
      "6  64000.0  40000.0   2000  190000.0\n",
      "7  76000.0   6000.0   2000  163000.0\n",
      "tmp_df1:\n",
      "   Unnamed: 0     apts    apts2  bonus    income\n",
      "0    Beijing  65000.0  10000.0   2000  147000.0\n",
      "1  Chongqing  64000.0  30000.0   2000  175000.0\n",
      "2  Guangzhou  47000.0   7000.0   2000  106500.0\n",
      "3   Hangzhou  64000.0      NaN   2000       NaN\n",
      "4   Shanghai  68000.0   8000.0   2000  150000.0\n",
      "5     Suzhou  64000.0      NaN   2000       NaN\n",
      "6    Tianjin  64000.0  40000.0   2000  190000.0\n",
      "7   shenzhen  76000.0   6000.0   2000  163000.0\n",
      "tmp_df3:\n",
      "           Unnamed: 0     apts    apts2  bonus    income\n",
      "Beijing      Beijing  65000.0  10000.0   2000  147000.0\n",
      "Shanghai   Chongqing  64000.0  30000.0   2000  175000.0\n",
      "Suzhou     Guangzhou  47000.0   7000.0   2000  106500.0\n",
      "Hangzhou    Hangzhou  64000.0      NaN   2000       NaN\n",
      "Tianjin     Shanghai  68000.0   8000.0   2000  150000.0\n",
      "Chongqing     Suzhou  64000.0      NaN   2000       NaN\n",
      "Nanjing      Tianjin  64000.0  40000.0   2000  190000.0\n",
      "Shenzhen    shenzhen  76000.0   6000.0   2000  163000.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cities={'Beijing':55000,'Shanghai':60000,'shenzhen':50000,'Hangzhou':20000,'Guangzhou':45000,'Suzhou':None}\n",
    "apts=pd.Series(cities,name='income')\n",
    "apts['shenzhen']=70000\n",
    "less_than_50000=(apts<50000)\n",
    "apts[less_than_50000]=40000\n",
    "apts2=pd.Series({'Beijing':10000,'Shanghai':8000,'shenzhen':6000,'Tianjin':40000,'Guangzhou':7000,'Chongqing':30000})\n",
    "apts=apts+apts2\n",
    "apts[apts.isnull()]=apts.mean()\n",
    "df=pd.DataFrame({'apts':apts,'apts2':apts2})\n",
    "df['bonus']=2000  \n",
    "df['income']=df['apts']*2+df['apts2']*1.5+df['bonus']\n",
    "print(\"df:\\n\",df)\n",
    "df.to_csv('df.csv')\n",
    "df.to_csv('df2.csv',index=False) #去掉第一列,行索引列\n",
    "\n",
    "import os\n",
    "df2_site = r\"C:\\Users\\jinlong\\df2.csv\"\n",
    "df_site = r\"C:\\Users\\jinlong\\df.csv\"\n",
    "pwd = os.getcwd()  #获取当前工作目录\n",
    "os.chdir(os.path.dirname(df2_site))\n",
    "tmp_df = pd.read_csv(os.path.basename(df2_site))   ###\n",
    "print(\"tmp_df2:\\n\",tmp_df)\n",
    "os.chdir(os.path.dirname(df_site))\n",
    "tmp_df = pd.read_csv(os.path.basename(df_site))   ###\n",
    "print(\"tmp_df1:\\n\",tmp_df)\n",
    "tmp_df_index = pd.Index(['Beijing','Shanghai',\"Suzhou\",'Hangzhou','Tianjin','Chongqing','Nanjing','Shenzhen'])\n",
    "tmp_df.index=tmp_df_index   #修改索引\n",
    "print(\"tmp_df3:\\n\",tmp_df)\n",
    "df.to_csv('df3.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_graph = tf.Graph()\n",
    "with new_graph.as_default():\n",
    "    new_g_const = tf.constant([1., 2.])\n",
    "default_g = tf.get_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first\n",
      "This is main of module \"hello.py\"\n",
      "hello\n",
      "__main__from hello.sayhello()\n",
      "__main__from hello.main\n"
     ]
    }
   ],
   "source": [
    "print(\"first\")\n",
    "\n",
    "\n",
    "def sayHello():\n",
    "    str = \"hello\"\n",
    "    print(str);\n",
    "    print(__name__+'from hello.sayhello()')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print ('This is main of module \"hello.py\"')\n",
    "    sayHello()\n",
    "    print(__name__+'from hello.main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first\n",
      "hello\n",
      "__main__from hello.sayhello()\n",
      "__main__from hello.main\n"
     ]
    }
   ],
   "source": [
    "print(\"first\")\n",
    "\n",
    "\n",
    "def sayHello():\n",
    "    str = \"hello\"\n",
    "    print(str);\n",
    "    print(__name__+'from hello.sayhello()')\n",
    "\n",
    "\n",
    "sayHello()\n",
    "print(__name__+'from hello.main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "\n",
    "california_housing_dataframe = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\", sep=\",\")\n",
    "\n",
    "california_housing_dataframe = california_housing_dataframe.reindex(\n",
    "    np.random.permutation(california_housing_dataframe.index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.feature_column.feature_column._NumericColumn'>\n",
      "households :\n",
      " _NumericColumn(key='households', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n"
     ]
    }
   ],
   "source": [
    "households = tf.feature_column.numeric_column(\"households\")\n",
    "#long_x_lat = tf.feature_column.crossed_column(\n",
    " # set([california_housing_dataframe[\"latitude\"], california_housing_dataframe[\"longitude\"]]), hash_bucket_size=1000)\n",
    "print(type(households))\n",
    "print(\"households :\\n\",households)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(california_housing_dataframe):\n",
    "  \"\"\"Prepares input features from California housing data set.\n",
    "\n",
    "  Args:\n",
    "    california_housing_dataframe: A Pandas DataFrame expected to contain data\n",
    "      from the California housing data set.\n",
    "  Returns:\n",
    "    A DataFrame that contains the features to be used for the model, including\n",
    "    synthetic features.\n",
    "  \"\"\"\n",
    "  selected_features = california_housing_dataframe[\n",
    "    [\"latitude\",\n",
    "     \"longitude\",\n",
    "     \"housing_median_age\",\n",
    "     \"total_rooms\",\n",
    "     \"total_bedrooms\",\n",
    "     \"population\",\n",
    "     \"households\",\n",
    "     \"median_income\"]]\n",
    "  processed_features = selected_features.copy()\n",
    "  # Create a synthetic feature.\n",
    "  processed_features[\"rooms_per_person\"] = (\n",
    "    california_housing_dataframe[\"total_rooms\"] /\n",
    "    california_housing_dataframe[\"population\"])\n",
    "  return processed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>rooms_per_person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4647</th>\n",
       "      <td>34.1</td>\n",
       "      <td>-118.1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1554.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>1427.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11567</th>\n",
       "      <td>37.8</td>\n",
       "      <td>-121.3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>830.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2313</th>\n",
       "      <td>34.9</td>\n",
       "      <td>-117.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9759.0</td>\n",
       "      <td>1816.0</td>\n",
       "      <td>2933.0</td>\n",
       "      <td>1168.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3370</th>\n",
       "      <td>33.9</td>\n",
       "      <td>-117.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2705.0</td>\n",
       "      <td>713.0</td>\n",
       "      <td>2726.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4519</th>\n",
       "      <td>33.7</td>\n",
       "      <td>-118.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2532.0</td>\n",
       "      <td>421.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       latitude  longitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "4647       34.1     -118.1                19.0       1554.0           393.0   \n",
       "11567      37.8     -121.3                26.0       1170.0           238.0   \n",
       "2313       34.9     -117.5                 7.0       9759.0          1816.0   \n",
       "3370       33.9     -117.9                18.0       2705.0           713.0   \n",
       "4519       33.7     -118.0                26.0       2532.0           421.0   \n",
       "\n",
       "       population  households  median_income  rooms_per_person  \n",
       "4647       1427.0       370.0            3.1               1.1  \n",
       "11567       830.0       216.0            2.6               1.4  \n",
       "2313       2933.0      1168.0            3.5               3.3  \n",
       "3370       2726.0       674.0            2.8               1.0  \n",
       "4519       1274.0       441.0            5.4               2.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_examples = preprocess_features(california_housing_dataframe.head(10))\n",
    "\n",
    "training_examples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type longitude:\n",
      " <class 'tensorflow.python.feature_column.feature_column._NumericColumn'>\n",
      "longitude:\n",
      " _NumericColumn(key='longitude', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "type bucketized_longitude:\n",
      " <class 'tensorflow.python.feature_column.feature_column._BucketizedColumn'>\n",
      "bucketized_longitude:\n",
      " _BucketizedColumn(source_column=_NumericColumn(key='longitude', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(-122.28, -121.98, -121.36000000000001, -119.87, -118.49, -118.3, -118.12, -117.88, -117.24))\n",
      "type long_x_lat:\n",
      " <class 'tensorflow.python.feature_column.feature_column._CrossedColumn'>\n",
      "long_x_lat:\n",
      " _CrossedColumn(keys=(_BucketizedColumn(source_column=_NumericColumn(key='latitude', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(33.839000000000006, 34.025999999999996, 34.616, 35.99, 37.285, 38.02, 38.323, 38.5, 39.242)), _BucketizedColumn(source_column=_NumericColumn(key='longitude', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(-122.28, -121.98, -121.36000000000001, -119.87, -118.49, -118.3, -118.12, -117.88, -117.24))), hash_bucket_size=100, hash_key=None)\n"
     ]
    }
   ],
   "source": [
    "def get_quantile_based_boundaries(feature_values, num_buckets):\n",
    "  boundaries = np.arange(1.0, num_buckets) / num_buckets\n",
    "  quantiles = feature_values.quantile(boundaries)\n",
    "  return [quantiles[q] for q in quantiles.keys()]\n",
    "\n",
    "longitude = tf.feature_column.numeric_column(\"longitude\")\n",
    "#longitude = tf.feature_column.numeric_column(training_examples[\"longitude\"])\n",
    "print(\"type longitude:\\n\",type(longitude))\n",
    "print(\"longitude:\\n\",longitude)\n",
    "#longitude=training_examples[\"longitude\"]\n",
    "#print(\"type longitude:\\n\",type(longitude))\n",
    "latitude = tf.feature_column.numeric_column(\"latitude\")\n",
    "bucketized_longitude = tf.feature_column.bucketized_column(\n",
    "  longitude, boundaries=get_quantile_based_boundaries(\n",
    "    california_housing_dataframe[\"longitude\"], 10))\n",
    "print(\"type bucketized_longitude:\\n\",type(bucketized_longitude))\n",
    "print(\"bucketized_longitude:\\n\",bucketized_longitude)\n",
    "#latitude=training_examples[\"latitude\"]\n",
    "bucketized_latitude = tf.feature_column.bucketized_column(\n",
    "    latitude, boundaries=get_quantile_based_boundaries(\n",
    "      training_examples[\"latitude\"], 10))\n",
    "long_x_lat = tf.feature_column.crossed_column(\n",
    "  set([bucketized_longitude, bucketized_latitude]), hash_bucket_size=100)\n",
    "print(\"type long_x_lat:\\n\",type(long_x_lat))\n",
    "print(\"long_x_lat:\\n\",long_x_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
